{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install [tinyBenchmarks](https://huggingface.co/datasets/tinyBenchmarks/tinyMMLU) For Efficient Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/felipemaiapolo/tinyBenchmarks\n",
      "  Cloning https://github.com/felipemaiapolo/tinyBenchmarks to /tmp/pip-req-build-luykhrgl\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/felipemaiapolo/tinyBenchmarks /tmp/pip-req-build-luykhrgl\n",
      "  Resolved https://github.com/felipemaiapolo/tinyBenchmarks to commit 9c7e20302301ad531bfdfd9a7288e6e916bf22e9\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /data/amos_zhu/miniconda3/envs/unlearn360/lib/python3.11/site-packages (from tinyBenchmarks==1.0.0) (1.26.2)\n",
      "Requirement already satisfied: scipy in /data/amos_zhu/miniconda3/envs/unlearn360/lib/python3.11/site-packages (from tinyBenchmarks==1.0.0) (1.14.1)\n",
      "Requirement already satisfied: requests in /data/amos_zhu/miniconda3/envs/unlearn360/lib/python3.11/site-packages (from tinyBenchmarks==1.0.0) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /data/amos_zhu/miniconda3/envs/unlearn360/lib/python3.11/site-packages (from requests->tinyBenchmarks==1.0.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /data/amos_zhu/miniconda3/envs/unlearn360/lib/python3.11/site-packages (from requests->tinyBenchmarks==1.0.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /data/amos_zhu/miniconda3/envs/unlearn360/lib/python3.11/site-packages (from requests->tinyBenchmarks==1.0.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/amos_zhu/miniconda3/envs/unlearn360/lib/python3.11/site-packages (from requests->tinyBenchmarks==1.0.0) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/felipemaiapolo/tinyBenchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate [CrystalChat](https://huggingface.co/LLM360/CrystalChat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-20:15:39:13,785 INFO     [__main__.py:272] Verbosity set to INFO\n",
      "2024-09-20:15:39:18,706 INFO     [__main__.py:369] Selected Tasks: ['tinyMMLU', 'wmdp_bio']\n",
      "2024-09-20:15:39:18,712 INFO     [evaluator.py:152] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-09-20:15:39:18,712 INFO     [evaluator.py:189] Initializing hf model, with arguments: {'pretrained': 'LLM360/CrystalChat', 'trust_remote_code': True}\n",
      "2024-09-20:15:39:18,746 INFO     [huggingface.py:170] Using device 'cuda'\n",
      "/data/amos_zhu/miniconda3/envs/unlearn360/lib/python3.11/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:06<00:00,  3.05s/it]\n",
      "2024-09-20:15:39:29,740 WARNING  [task.py:325] [Task: wmdp_bio] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-09-20:15:39:29,740 WARNING  [task.py:325] [Task: wmdp_bio] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-09-20:15:39:29,802 INFO     [evaluator.py:261] Setting fewshot random generator seed to 1234\n",
      "2024-09-20:15:39:29,802 INFO     [evaluator.py:261] Setting fewshot random generator seed to 1234\n",
      "2024-09-20:15:39:29,806 INFO     [task.py:411] Building contexts for wmdp_bio on rank 0...\n",
      "100%|██████████████████████████████████████| 1273/1273 [00:01<00:00, 957.37it/s]\n",
      "2024-09-20:15:39:31,169 INFO     [task.py:411] Building contexts for tinyMMLU on rank 0...\n",
      "100%|███████████████████████████████████████| 100/100 [00:00<00:00, 4137.95it/s]\n",
      "2024-09-20:15:39:31,198 INFO     [evaluator.py:438] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|██████| 5492/5492 [00:25<00:00, 211.71it/s]\n",
      "2024-09-20:15:40:03,493 INFO     [evaluation_tracker.py:240] Output path not provided, skipping saving results aggregated\n",
      "hf (pretrained=LLM360/CrystalChat,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 16\n",
      "| Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
      "|--------|------:|------|-----:|--------|---|-----:|---|------|\n",
      "|tinyMMLU|      0|none  |     0|acc_norm|↑  |0.4997|±  |N/A   |\n",
      "|wmdp_bio|      0|none  |     0|acc     |↑  |0.5774|±  |0.0139|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!lm-eval --model hf \\\n",
    "    --model_args pretrained=LLM360/CrystalChat,trust_remote_code=True \\\n",
    "    --tasks tinyMMLU,wmdp_bio \\\n",
    "    --batch_size=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unlearn CrystalChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/amos_zhu/miniconda3/envs/unlearn360/lib/python3.11/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.59s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading bio-forget dataset: 100%|█████████████| 100/100 [00:01<00:00, 69.87it/s]\n",
      "Loading wikitext-test dataset: 100%|████████| 100/100 [00:00<00:00, 2117.24it/s]\n",
      "Total Loss: -8.1836, Retain Loss: 2.1133, Forget Loss: -10.2969: 100%|█| 25/25 [\n",
      "Log saved to log.json\n",
      "Removed shared tensor {'lm_head.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n",
      "Model saved to ./models/max-entropy_bio-forget_wikitext-test_CrystalChat\n"
     ]
    }
   ],
   "source": [
    "!python unlearn.py --model_name_or_path LLM360/CrystalChat --unlearn_method max-entropy --lr 5e-5 --random_seed 23597 --min_len 50 --max_len 1000 --max_unlearn_steps 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Unlearned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-20:15:48:36,495 INFO     [__main__.py:272] Verbosity set to INFO\n",
      "2024-09-20:15:48:40,925 INFO     [__main__.py:369] Selected Tasks: ['tinyMMLU', 'wmdp_bio']\n",
      "2024-09-20:15:48:40,928 INFO     [evaluator.py:152] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-09-20:15:48:40,928 INFO     [evaluator.py:189] Initializing hf model, with arguments: {'pretrained': './models/max-entropy_bio-forget_wikitext-test_CrystalChat', 'trust_remote_code': True}\n",
      "2024-09-20:15:48:40,970 INFO     [huggingface.py:170] Using device 'cuda'\n",
      "/data/amos_zhu/miniconda3/envs/unlearn360/lib/python3.11/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:02<00:00,  1.35it/s]\n",
      "2024-09-20:15:48:47,025 WARNING  [task.py:325] [Task: wmdp_bio] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-09-20:15:48:47,025 WARNING  [task.py:325] [Task: wmdp_bio] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-09-20:15:48:47,057 INFO     [evaluator.py:261] Setting fewshot random generator seed to 1234\n",
      "2024-09-20:15:48:47,057 INFO     [evaluator.py:261] Setting fewshot random generator seed to 1234\n",
      "2024-09-20:15:48:47,060 INFO     [task.py:411] Building contexts for wmdp_bio on rank 0...\n",
      "100%|██████████████████████████████████████| 1273/1273 [00:01<00:00, 950.72it/s]\n",
      "2024-09-20:15:48:48,432 INFO     [task.py:411] Building contexts for tinyMMLU on rank 0...\n",
      "100%|███████████████████████████████████████| 100/100 [00:00<00:00, 4091.09it/s]\n",
      "2024-09-20:15:48:48,460 INFO     [evaluator.py:438] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|██████| 5492/5492 [00:25<00:00, 212.47it/s]\n",
      "2024-09-20:15:49:17,684 WARNING  [huggingface.py:1315] Failed to get model SHA for ./models/max-entropy_bio-forget_wikitext-test_CrystalChat at revision main. Error: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './models/max-entropy_bio-forget_wikitext-test_CrystalChat'. Use `repo_type` argument if needed.\n",
      "2024-09-20:15:49:20,624 INFO     [evaluation_tracker.py:240] Output path not provided, skipping saving results aggregated\n",
      "hf (pretrained=./models/max-entropy_bio-forget_wikitext-test_CrystalChat,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 16\n",
      "| Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
      "|--------|------:|------|-----:|--------|---|-----:|---|------|\n",
      "|tinyMMLU|      0|none  |     0|acc_norm|↑  |0.4199|±  |N/A   |\n",
      "|wmdp_bio|      0|none  |     0|acc     |↑  |0.3991|±  |0.0137|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!lm-eval --model hf \\\n",
    "    --model_args pretrained=./models/max-entropy_bio-forget_wikitext-test_CrystalChat,trust_remote_code=True \\\n",
    "    --tasks tinyMMLU,wmdp_bio \\\n",
    "    --batch_size=16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unlearn360",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
